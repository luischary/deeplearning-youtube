# 02_rnn_text_corrector

<a href="https://youtube.com/playlist?list=PLxn5KTcVccYFDGqKMaqfa62RFj2Q5WAaN&si=j8Mnj_LdGv3jENCH" target="_blank">
  <img src="https://img.shields.io/badge/Assistir_no_YouTube-FF0000?style=for-the-badge&logo=youtube&logoColor=white" alt="Assistir no YouTube"/>
</a>

## 游닇 Sobre este projeto
Neste projeto implementaremos uma rede neural recorrente (RNN) no formato encoder-decoder que far치 corre칞칚o de texto!

**T칩picos abordados:**
- Dados e prepara칞칚o - [1_DATAPREP.ipynb](./1_DATAPREP.ipynb)
- Remo칞칚o de duplicidade de textos com Hash e MinHashLSH ()
    - Remo칞칚o de duplicidade padr칚o em mem칩ria RAM - [duplicidade.py](./duplicidade.py)
    - Remo칞칚o de duplicidade customizada para caber na mem칩ria - [duplicidade_custom.py](./duplicidade_custom.py)
    - Remo칞칚o de duplicidade customizada e R츼PIDA - [duplicidade_custom_parallel.py](./duplicidade_custom_parallel.py)
- Cria칞칚o dos componentes (tokenizador, dataset, scheduler e modelo) - [src](./src/)
- Loop de treinamento [train.py](train.py) e Loop de treinamento avan칞ado [train_plus.py](train_plus.py)
- (INCOMPLETO) Script de infer칡ncia [inference.py](inference.py)
- (EM BREVE) Script de avalia칞칚o

**Datasets mostrados no v칤deo**:
* [Wikipedia PT Dump](https://dumps.wikimedia.org/ptwiki/20260101/)
* [OPUS - OpenSubtitles](https://opus.nlpl.eu/OpenSubtitles/en&pt/v2024/OpenSubtitles)

**Datasets que eu utilizei**:
- [Base do wikipedia (202512) tratada](https://drive.google.com/file/d/1JGthoy7aWbU9xz1rGoRxD_epaRZGAsSI/view?usp=sharing)
- [Dataset de treinamento (sem duplicidade)](https://drive.google.com/file/d/1pqgHJd-VplJOabLgvcHv93quAO7Uv6KB/view?usp=sharing)
- [Dataset de valida칞칚o](https://drive.google.com/file/d/1PlQJbCxcrCQFFKyRUziaWVQTSyGcDWEr/view?usp=sharing)